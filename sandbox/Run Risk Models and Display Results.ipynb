{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models for Hindcasting\n",
    "\n",
    "This notebook allows you to run a few models for estimating the risk of crime in grid cells over a given area (such as Durham) via a few different types of models.\n",
    "\n",
    "The following models are currently implemented:\n",
    "- Random: Rank all cells completely randomly. Baseline lowest-performing model.\n",
    "- Naive: Count the number of events per cell.\n",
    "- PHS: Each event spreads risk radially outward, decreasing in time and space depending on the parameters given to it.\n",
    "- Ideal: Impossibly ideal model that \"cheats\" by reading the testing data instead of the training data. Baseline highest-performing model.\n",
    "\n",
    "Specifically, this notebook is designed to evaluate the efficacy of these models by testing them against historic data. Alternatively, if you are only interested in obtaining a forecast of the highest-risk locations within a region based on previous history of crime events in the region, see the related \"forecasting\" notebook instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n",
    "\n",
    "Necessary modules are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "# Import necessary tools from modules.\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "import riskModelsGeneric\n",
    "import crimeRiskTimeTools\n",
    "import geodataTools\n",
    "import importlib\n",
    "importlib.reload(riskModelsGeneric)\n",
    "importlib.reload(crimeRiskTimeTools)\n",
    "importlib.reload(geodataTools)\n",
    "from riskModelsGeneric import runModelExperiments, \\\n",
    "                                std_file_name, \\\n",
    "                                graph_cov_vs_hit_from_csv, \\\n",
    "                                loadGenericData\n",
    "from crimeRiskTimeTools import getSixDigitDate\n",
    "from geodataTools import list_risk_model_properties, \\\n",
    "                         top_geojson_features, \\\n",
    "                         marker_cluster_from_data, \\\n",
    "                         combine_geojson_features, \\\n",
    "                         json_dict_to_geoframe\n",
    "\n",
    "print(\"Successfully imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Your Data\n",
    "\n",
    "Identify one data directory that will contain your input files, and another directory that will contain the output files generated by this notebook. (These can be the same directory.)\n",
    "\n",
    "In your input directory, you should place these files:\n",
    "- Input CSV file of crime events. The first line of the file should be a header, with appropriate labels for its columns. 4 columns must contain the information listed below for each crime event; other columns will be ignored. The expected formats of the data can be changed as needed via additional parameters discussed later.\n",
    "    - Time and date\n",
    "    - East/West coordinate; could be Eastings or Longitude\n",
    "    - North/South coordinate; could be Northings or Latitude\n",
    "    - Crime type, e.g. Burglary\n",
    "    - Any other columns will be ignored.\n",
    "    - The first line of the file should be a header, with appropriate labels for these columns.\n",
    "- Geojson file that will generate a polygon of the relevant region\n",
    "    - For Chicago, this can be found at:\n",
    "        - https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6\n",
    "    - For regions of the UK, here is one process of generating a file from Ordnance Survey data:\n",
    "        - Visit https://www.ordnancesurvey.co.uk/opendatadownload/products.html\n",
    "        - Scroll down to the \"Boundary-Line\" data, select ESRI SHAPE format, click the \"Download\" box, then scroll to the bottom and click \"Continue\".\n",
    "        - After requesting the download from the next page, wait for a download link to be sent to your email, which should allow you to download a \"force_kmls.zip\" file full of .kml files.\n",
    "        - Use the \"ogr2ogr\" tool to convert the relevant .kml file to .geojson, as in the following command: \"ogr2ogr -f GeoJSON durham.geojson durham.kml\"\n",
    "        - The resulting GeoJSON file will have its coordinates in longitude an latitude. Optionally, you may convert that geojson file to a new one that has a UK-specific projection (EPSG 27700); this can be done with the function convertGeojsonUKCounty in onetimeruns.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "\n",
    "Set your parameters here. The current default arguments are for a Fantasy Durham data set; examples of further options are shown on commented-out lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edit these parameters, then run this.\n",
    "\n",
    "\n",
    "# Your input directory, containg your input data files discussed above\n",
    "input_datadir = \"../../PredictData/Durham\"\n",
    "\n",
    "# Your intended directory for the output files that will be generated\n",
    "output_datadir = \"../../Output\"\n",
    "\n",
    "# Name of your input csv file of crime data\n",
    "in_csv_file_name = \"Fantasy-Durham-Data.csv\"\n",
    "\n",
    "# Names of the appropriate columns in the header of the csv file\n",
    "#    column with date (and possibly time)\n",
    "csv_date_name       = \"Date\"\n",
    "#    column with eastings or longitudes\n",
    "csv_east_name       = \"Longitude\"\n",
    "#    column with northings or latitudes\n",
    "csv_north_name      = \"Latitude\"\n",
    "#    column with type of crime\n",
    "csv_crimetypes_name = \"Crime type\"\n",
    "\n",
    "# Name of your input GeoJSON file of the relevant region\n",
    "#area_geojson_file_name = \"Police_Force_Areas_December_2016_Durham_fixed.geojson\"\n",
    "area_geojson_file_name = \"Darlington-LSOA-test.geojson\"\n",
    "\n",
    "# Concise name for your crime data set, to be included as part of output file names\n",
    "#  Note: Any characters that are not letters or numbers will be removed\n",
    "dataset_name = \"FantDur\"\n",
    "\n",
    "# Relevant crime types, as named in the crime type column of your input file\n",
    "#  If you want to aggregate multiple crime types, you can separate them by commas\n",
    "#crime_type_set = \"Burglary, Vehicle crime\"\n",
    "crime_type_set = \"Burglary\"\n",
    "#crime_type_set = \"Vehicle crime\"\n",
    "\n",
    "# Size (in meters) of the side of squares in the grid over the area\n",
    "cell_width = 200\n",
    "\n",
    "\n",
    "\n",
    "# Total number of experiments to run\n",
    "#  Multiple experiments will each be offset by \"time_step\", below\n",
    "num_experiments    = 12\n",
    "\n",
    "\n",
    "# The date associated with the first experiment\n",
    "#  This should be the first day AFTER the training data window,\n",
    "#  which is also the first day of the testing data window,\n",
    "#  for the first experiment.\n",
    "#  (Currently, provide date in format YYYY-MM-DD)\n",
    "earliest_exp_date = \"2019-09-15\"\n",
    "\n",
    "# For time length parameters, use a number followed by a letter.\n",
    "#  D=days, W=weeks, M=months, Y=years\n",
    "#  3D=3 days, 12W=12 weeks, 6M=6 months, 1Y=1 year, etc\n",
    "\n",
    "# Size of the time window of events for the models to be trained on in each experiment\n",
    "train_len          = \"8W\"\n",
    "\n",
    "# Size of the subsequent time window of events for the models to be tested on in each experiment\n",
    "test_len           = \"1W\"\n",
    "\n",
    "# Time step offset between different experiments\n",
    "# If set to None, then test_date_step = test_len\n",
    "#  (so that the experiments' testing windows are adjacent and non-overlapping)\n",
    "# If only one experiment is performed, then this parameter has no effect.\n",
    "test_date_step     = None\n",
    "#test_date_step     = \"1W\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Coverage rates to test and record, comma-separated as needed\n",
    "coverage_bounds = \"0.001,0.002,0.005,0.01\"\n",
    "\n",
    "# Predictive model(s) to run, comma-separated if running multiple different ones\n",
    "#  Currently recognised names ares: random, naive, ideal, phs\n",
    "models_to_run = \"naive,phs\"\n",
    "\n",
    "\n",
    "# Parameters for PHS model, each one comma-separated as needed\n",
    "#  Atomic unit for time bandwidths\n",
    "phs_time_units = \"1W\"\n",
    "#  Time bandwidths -- should be a multiple of phs_time_units\n",
    "phs_time_bands = \"4W,8W\"\n",
    "#  Atomic unit for distance bandwidths, in meters\n",
    "#   Recommended to set this equal to cell_width\n",
    "phs_dist_units = \"200\"\n",
    "#  Distance bandwidths, in meters -- should be a multiple of phs_dist_units\n",
    "phs_dist_bands = \"400,800\"\n",
    "#  Weight function\n",
    "#   \"classic\": \n",
    "#   \"linear\": \n",
    "phs_weight = \"classic\"\n",
    "#  Spread type\n",
    "#   \"grid\": \n",
    "#   \"continuous\": \n",
    "phs_spread = \"continuous\"\n",
    "\n",
    "# CSV formatting parameters\n",
    "# If Fantasy Durham data:\n",
    "local_epsg = 27700\n",
    "csv_date_format = \"%d/%m/%Y\"\n",
    "csv_longlat = True\n",
    "csv_epsg = 27700\n",
    "csv_infeet = False\n",
    "\n",
    "\n",
    "\n",
    "print(\"Parameter assignment complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments using various models and data subsets\n",
    "\n",
    "This function (runModelExperiments) takes the parameters from above and runs the models with all desired parameter combinations, using training and testing data sets over sliding-window timeframes.\n",
    "\n",
    "A csv output file will appear in the defined data directory, containing results from each model with each parameter combination on each timeframe's data set.\n",
    "\n",
    "If only 1 data timeframe is used, heatmap visualisations will be generated, appearing below as well as in the same defined data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "created_files = runModelExperiments(\n",
    "        input_datadir_in = input_datadir, \n",
    "        output_datadir_in = output_datadir, \n",
    "        dataset_name_in = dataset_name, \n",
    "        crime_type_set_in = crime_type_set, \n",
    "        cell_width_in = cell_width, \n",
    "        in_csv_file_name_in = in_csv_file_name, \n",
    "        geojson_file_name_in = area_geojson_file_name, \n",
    "        local_epsg_in = local_epsg, \n",
    "        earliest_exp_date_in = earliest_exp_date, \n",
    "        num_experiments_in = num_experiments, \n",
    "        train_len_in = train_len, \n",
    "        test_len_in = test_len, \n",
    "        test_date_step_in = test_date_step, \n",
    "        coverage_bounds_in = coverage_bounds, \n",
    "        models_to_run_in = models_to_run, \n",
    "        phs_time_units_in = phs_time_units, \n",
    "        phs_time_bands_in = phs_time_bands, \n",
    "        phs_dist_units_in = phs_dist_units, \n",
    "        phs_dist_bands_in = phs_dist_bands, \n",
    "        phs_weight_in = phs_weight, \n",
    "        phs_spread_in = phs_spread, \n",
    "        csv_date_format = csv_date_format, \n",
    "        csv_longlat = csv_longlat, \n",
    "        csv_epsg = csv_epsg, \n",
    "        csv_infeet = csv_infeet, \n",
    "        csv_col_names = [csv_date_name, csv_east_name, csv_north_name, csv_crimetypes_name], \n",
    "        )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Full list of file names:\")\n",
    "for fname in created_files:\n",
    "    print(fname)\n",
    "if int(test_len[:-1])==0:\n",
    "    created_files = [None] + created_files\n",
    "results_csv_file, train_geojson_file, test_geojson_file, details_csv_file, results_geojson_file = created_files[:5]\n",
    "print(\"\")\n",
    "print(\"Results csv file:\")\n",
    "print(results_csv_file)\n",
    "print(\"First training data geojson file:\")\n",
    "print(train_geojson_file)\n",
    "print(\"First testing data geojson file:\")\n",
    "print(test_geojson_file)\n",
    "print(\"First detailed results csv file:\")\n",
    "print(details_csv_file)\n",
    "print(\"First detailed results geojson file:\")\n",
    "print(results_geojson_file)\n",
    "\n",
    "print(\"\\nProcessing complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View output of hindcasting\n",
    "\n",
    "If you've generated a csv file of hindcasting results, you can easily view the relevant output by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optionally, run this without editing anything\n",
    "\n",
    "\n",
    "hindcasting_output = pd.read_csv(results_csv_file)\n",
    "hindcasting_output.sort_values([\"eval_date\", \"coverage_rate\", \"hit_pct\"], \n",
    "                               axis=0, ascending=True, inplace=True)\n",
    "\n",
    "# Select columns to display\n",
    "hindcasting_dataframe = \\\n",
    "        hindcasting_output[['eval_date', \n",
    "                            'event_types',\n",
    "                            'train_len', \n",
    "                            'test_len', \n",
    "                            'test_events', \n",
    "                            'hit_count', \n",
    "                            'model',\n",
    "                            'time_band', \n",
    "                            'dist_band', \n",
    "                            'coverage_rate', \n",
    "                            'hit_pct']]\n",
    "\n",
    "# Set NaN values to the empty string prior to display\n",
    "hindcasting_dataframe = hindcasting_dataframe.fillna(\"\")\n",
    "\n",
    "# Display dataframe\n",
    "hindcasting_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Output from a Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = sns.barplot(x=\"coverage_rate\",y=\"hit_pct\",hue=\"model\", data=hindcasting_output)\n",
    "g.set(ylabel=\"Proportion Crimes\", xlabel=\"Proprtion Area\", title =\"Hit rate - area vs crime\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a detailed csv file has been generated, a line graph of the results can be viewed by running this code, after editing the parameters appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optionally, edit this then run it\n",
    "\n",
    "\n",
    "# Detailed csv file\n",
    "# This already would have been set to the 1st detailed file generated,\n",
    "#  but you can replace it here with a path to a different file if you'd like\n",
    "#details_csv_file = \"../../Output/details_200203_FantDur_Burglary-Vehiclecrime_500m_190915_3x_1W_4W_1W_2.csv\"\n",
    "\n",
    "# Bounds of the x-axis, corresponding to coverage rate\n",
    "coverage_range = [0, 0.1]\n",
    "\n",
    "# Title for the graph (if no title, set to None)\n",
    "#graph_title = None\n",
    "graph_title = \"Coverage vs Hit Rate\"\n",
    "\n",
    "# Dimensions of output graph (if None, will be (12,6))\n",
    "graph_size = None\n",
    "graph_size = (12,8)\n",
    "\n",
    "\n",
    "# If you want to save the line graph, provide a file name here\n",
    "img_file_path = None\n",
    "#img_file_path = \"../../Output/details_200130_FantDur_Burglary_500m_190915_1x_1W_4W_1W_1.png\"\n",
    "\n",
    "\n",
    "graph_cov_vs_hit_from_csv(details_csv_file, \n",
    "                          x_limits = coverage_range, \n",
    "                          title = graph_title, \n",
    "                          img_size = graph_size, \n",
    "                          out_img_file_path = img_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Multiple Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(x=\"eval_date\",y=\"hit_pct\",hue=\"model\", data=hindcasting_dataframe.loc[hindcasting_dataframe['coverage_rate'] == 0.01])\n",
    "g.set(ylabel=\"Proportion Crimes\", xlabel=\"Prediction Date\", title =\"Hit rate over time\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conda installing Ipyleaflet, we need to enable some notebook extensions and import its functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "from ipyleaflet import *\n",
    "print(\"Successfully imported ipyleaflet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you successfully ran runModelExperiments above, performing only one experiment so that a \"results\" GeoJSON file is generated, then these file paths to the GeoJSON files will already be saved, so you don't need to run this section.\n",
    "\n",
    "However, if you want to examine a different previously created file, then you can declare the full paths of those GeoJSON files yourself, here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional; only edit & run this if desired\n",
    "\n",
    "# Name of GeoJson file with training data's events\n",
    "train_geojson_file = \"../../Data/train_200115_FantDur_190901_1W_1W_4W_1W.geojson\"\n",
    "\n",
    "# Name of GeoJson file with testing data's events\n",
    "test_geojson_file = \"../../Data/test_200115_FantDur_190901_1W_1W_4W_1W.geojson\"\n",
    "\n",
    "# Name of GeoJson file with risk scores for relevant cells\n",
    "results_geojson_file = \"../../Data/results_200115_FantDur_190901_1W_1W_4W_1W.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from the results GeoJSON file, and display a list of properties from the results GeoJSON that can be selected for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing\n",
    "\n",
    "with open(results_geojson_file) as cg:\n",
    "    cell_results = json.load(cg)\n",
    "print(f\"Successfully read geojson data from {results_geojson_file}\\n\")\n",
    "\n",
    "print('Properties available to visualize as \"property_to_map\":\\n')\n",
    "for p in list_risk_model_properties(geojson_file_contents=cell_results):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use this section if you want to combine properties together to make a new property, which will be saved off into a new GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional; only edit & run this if desired\n",
    "\n",
    "# The geojson data (or, file names) with the info you want to combine.\n",
    "# If it's all from the same data, just give the file name or the data object\n",
    "# If you're pulling from multiple geojson files, make a list of them, \n",
    "#  repeating them for as many properties you're taking from them.\n",
    "# For example, if you're combining 2 properties from geojsonA and 1 property\n",
    "#  from geojsonB, this would be [geojsonA, geojsonA, geojsonB]\n",
    "\n",
    "geojson_data_to_combine = [\"../../Output/results_200129_FantDur_Burglary_500m_190915_1x_1W_4W_1W.geojson\", \n",
    "                           \"../../Output/results_200129_FantDur_Burglary_500m_190915_1x_1W_4W_1W.geojson\"]\n",
    "\n",
    "# The crime type analysed for each file\n",
    "crime_type_set = \"Burglary, Vehicle crime\"\n",
    "\n",
    "# The names of the properties you're combining.\n",
    "# If it's the same property name from all the geojsons, just name it here.\n",
    "# If you want multiple properties, make a list of them here,\n",
    "#  corresponding to the list of geojsons in geojson_data_to_combine\n",
    "\n",
    "properties_to_combine = \"phs-4W-1500m, phs-4W-1500m\"\n",
    "\n",
    "# The relative weights to place on each property.\n",
    "# For example, if you consider the second property to be three times as \n",
    "#  important as the first property, then use [1, 3] here.\n",
    "# That would create a new property that is equal to the sum of\n",
    "#  the first property and treble the second property.\n",
    "\n",
    "property_weights = [2,1]\n",
    "\n",
    "# The name for the new combined property you create.\n",
    "# If this is not included or set to None, then the name of the property\n",
    "#  will be the names of all the other properties, combined with \"_\"\n",
    "\n",
    "combined_property_name = \"triple-test\"\n",
    "\n",
    "# The name for the output GeoJSON file containing the combined property.\n",
    "# If this is not included or set to None, then the name of the file\n",
    "#  will be \"results_{combined_property_name}.geojson\" and it will be\n",
    "#  placed in the same directory as the first GeoJSON file listed in\n",
    "#  the list geojson_data_to_combine.\n",
    "\n",
    "combined_geojson_file_path = None\n",
    "\n",
    "# The combined property is created here\n",
    "\n",
    "cell_results, new_property_name, new_geojson_file = combine_geojson_features(\n",
    "                        geojson_data_list     = geojson_data_to_combine, \n",
    "                        combine_property_list = properties_to_combine, \n",
    "                        multiplier_list       = property_weights, \n",
    "                        new_property_name     = combined_property_name, \n",
    "                        new_file_name         = combined_geojson_file_path, \n",
    "                        )\n",
    "\n",
    "print(f\"Combined properties to make new property: {new_property_name}\")\n",
    "print(f\"New GeoJSON file saved at: {new_geojson_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name the property you want to view on an interactive map here, along with other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edit this, then run it\n",
    "\n",
    "# The property you want to map from the results file\n",
    "#property_to_map = \"naive\"\n",
    "property_to_map = \"phs-4W-1500m\"\n",
    "#property_to_map = \"phs-combo\"\n",
    "\n",
    "# The top proportion of cells you want to highlight\n",
    "highlight_portion = 0.01\n",
    "\n",
    "# The style of highlighted cells\n",
    "highlight_cell_style = {'color':'blue',\n",
    "                        'weight':1.5,\n",
    "                        'fillColor':'transparent',\n",
    "                       }\n",
    "\n",
    "# Whether you want to plot the events from the training data\n",
    "#  Choose from:\n",
    "#   \"none\"    : Do not display the events\n",
    "#   \"point\"   : Each event is a slightly transparent black circle\n",
    "#   \"cluster\" : Multiple events cluster together as single circles,\n",
    "#                 changing at different zoom levels\n",
    "show_training_events = \"cluster\"\n",
    "\n",
    "# Whether you want to plot the events from the testing data\n",
    "#  Choose either True or False\n",
    "show_testing_events = True\n",
    "\n",
    "\n",
    "\n",
    "# Whether you want to save the top proportion of cells as a GeoJSON\n",
    "#  file for later use, perhaps focusing solely on those areas.\n",
    "#  This will create a file in the ouput directory, with a name\n",
    "#  formatted as \"top-cells_(property name)_(proportion).geojson\"\n",
    "save_top_cells = True\n",
    "\n",
    "print(\"Parameters for map display have been set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "# Instantiate a map centred at Durham\n",
    "#m = Map(center=[54.776100, -1.573300], zoom=10)\n",
    "m = Map(center=[54.75, -1.573300], zoom=9)\n",
    "\n",
    "# We now load the police force area GeoJSON file and add it as a layer to the map\n",
    "with open(std_file_name([input_datadir, area_geojson_file_name]), 'r') as f:\n",
    "    bounds = json.load(f)\n",
    "bounds_layer = GeoJSON(data=bounds, style = {'color': 'green', 'opacity':1, 'weight':2, 'fillColor':'transparent'})\n",
    "m.add_layer(bounds_layer)\n",
    "\n",
    "# Obtain relevant scores from GeoJSON file, and only include\n",
    "#  cells with non-zero scores\n",
    "score_mapping = dict()\n",
    "nonzero_cell_results = dict()\n",
    "for key in cell_results:\n",
    "    if key != 'features':\n",
    "        nonzero_cell_results[key] = cell_results[key]\n",
    "nonzero_cell_results['features'] = []\n",
    "for feat in cell_results['features']:\n",
    "    property_value = feat['properties'][property_to_map]\n",
    "    if property_value > 0:\n",
    "        nonzero_cell_results['features'].append(feat)\n",
    "    score_mapping[feat['id']] = property_value\n",
    "\n",
    "\n",
    "# Create map layer with color-coded cells reperenting risk scores, like a heat map\n",
    "from branca.colormap import linear\n",
    "layer = Choropleth(\n",
    "    geo_data=nonzero_cell_results,\n",
    "    choro_data=score_mapping,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='transparent',\n",
    "    style={'fillOpacity': 0.8})\n",
    "m.add_layer(layer)\n",
    "\n",
    "\n",
    "# Create map layer of crime events from training data\n",
    "if show_training_events != None:\n",
    "    show_training_events = show_training_events.lower()\n",
    "    if show_training_events not in [\"false\",\"no\",\"none\"]:\n",
    "        if show_training_events == \"point\":\n",
    "            with open(train_geojson_file) as eg:\n",
    "                datapoints = json.load(eg)\n",
    "            geojson_datapoints = GeoJSON(data=datapoints, point_style={'color': 'transparent', 'fillColor': 'black', 'radius': 5})\n",
    "            m.add_layer(geojson_datapoints)\n",
    "        elif show_training_events == \"cluster\":\n",
    "            cluster_datapoints = marker_cluster_from_data(train_geojson_file)\n",
    "            m.add_layer(cluster_datapoints)\n",
    "\n",
    "# Create map layer of crime events from testing data\n",
    "if show_testing_events:\n",
    "    with open(test_geojson_file) as eg_2:\n",
    "        test_datapoints = json.load(eg_2)\n",
    "    geojson_test_datapoints = GeoJSON(data=test_datapoints, point_style={'color': 'transparent', 'fillColor': 'green', 'radius': 5})\n",
    "    m.add_layer(geojson_test_datapoints)\n",
    "    \n",
    "\n",
    "\n",
    "# Create map layer where top % of cells are highlighted\n",
    "cell_results_gdf = json_dict_to_geoframe(cell_results)\n",
    "top_cells_frame = top_geojson_features(cell_results_gdf, property_to_map, highlight_portion)\n",
    "top_cells_layer = GeoData(geo_dataframe = top_cells_frame,\n",
    "                         style = highlight_cell_style)\n",
    "m.add_layer(top_cells_layer)\n",
    "if save_top_cells:\n",
    "    top_cells_geojson_file = std_file_name([output_datadir, \n",
    "                f\"top-cells_{property_to_map}_{str(highlight_portion)[2:]}.geojson\"])\n",
    "    cell_results_gdf.to_file(top_cells_geojson_file, driver='GeoJSON')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add useful controls to the GUI for full screen mode and layer toggling\n",
    "m.add_control(FullScreenControl())\n",
    "m.add_control(LayersControl())\n",
    "\n",
    "\n",
    "# Display useful information as text above the map\n",
    "num_cells = len(cell_results['features'])\n",
    "sqkm_per_cell = ((cell_width*.001)**2)\n",
    "area_size = num_cells * sqkm_per_cell\n",
    "num_cells_highlight = int(num_cells * highlight_portion)\n",
    "area_highlight = num_cells_highlight * sqkm_per_cell\n",
    "date_time_now = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M\")\n",
    "message = (\n",
    "    f\"Generating map...... {date_time_now}\\n\", \n",
    "    f\"Crime Type Analysed: {crime_type_set}\\n\", \n",
    "    f\"Mapping: {property_to_map}\\n\", \n",
    "    f\"Grid Config:\\n\",\n",
    "    f\"  Grid cell size: {cell_width}m x {cell_width}m\\n\",\n",
    "    f\"  {num_cells} grid cells analysed\\n\",\n",
    "    f\"  Total area: {area_size:.2f} km^2 \\n\",\n",
    "    f\"Priority Cells:\\n\",\n",
    "    f\"  Coverage {highlight_portion * 100}%\\n\",\n",
    "    f\"  Number of cells: {num_cells_highlight}\\n\",\n",
    "    f\"  Priority area: {area_highlight:.2f} km^2\\n\",\n",
    ")\n",
    "print(*message)\n",
    "\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
