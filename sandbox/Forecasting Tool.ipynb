{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models for Forecasting\n",
    "\n",
    "This notebook allows you to run a few models for estimating the risk of crime in grid cells over a given area (such as Durham) via a few different types of models.\n",
    "\n",
    "The following models are currently implemented:\n",
    "- Random: Rank all cells completely randomly. Baseline lowest-performing model.\n",
    "- Naive: Count the number of events per cell.\n",
    "- PHS: Each event spreads risk radially outward, decreasing in time and space depending on the parameters given to it.\n",
    "- Ideal: Impossibly ideal model that \"cheats\" by reading the testing data instead of the training data. Baseline highest-performing model.\n",
    "\n",
    "Specifically, this notebook is designed to simply provide a forecast of the highest-risk locations within a region, given previous history of crime events in the region. Alternatively, if you are interested in evaluating the efficacy of these models by testing them against historic data, see the related \"hindcasting\" notebook instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n",
    "\n",
    "Necessary modules are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported modules.\n"
     ]
    }
   ],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "# Import necessary tools from modules.\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "import riskModelsGeneric\n",
    "import crimeRiskTimeTools\n",
    "import geodataTools\n",
    "import importlib\n",
    "importlib.reload(riskModelsGeneric)\n",
    "importlib.reload(crimeRiskTimeTools)\n",
    "importlib.reload(geodataTools)\n",
    "from riskModelsGeneric import runModelExperiments, \\\n",
    "                                std_file_name, \\\n",
    "                                graph_cov_vs_hit_from_csv, \\\n",
    "                                loadGenericData\n",
    "from crimeRiskTimeTools import getSixDigitDate\n",
    "from geodataTools import list_risk_model_properties, \\\n",
    "                         top_geojson_features, \\\n",
    "                         marker_cluster_from_data, \\\n",
    "                         combine_geojson_features, \\\n",
    "                         json_dict_to_geoframe\n",
    "\n",
    "print(\"Successfully imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Your Data\n",
    "\n",
    "Identify one data directory that will contain your input files, and another directory that will contain the output files generated by this notebook. (These can be the same directory.)\n",
    "\n",
    "In your input directory, you should place these files:\n",
    "- Input CSV file of crime events. The first line of the file should be a header, with appropriate labels for its columns. 4 columns must contain the information listed below for each crime event; other columns will be ignored. The expected formats of the data can be changed as needed via additional parameters discussed later.\n",
    "    - Time and date\n",
    "    - East/West coordinate; could be Eastings or Longitude\n",
    "    - North/South coordinate; could be Northings or Latitude\n",
    "    - Crime type, e.g. Burglary\n",
    "    - Any other columns will be ignored.\n",
    "    - The first line of the file should be a header, with appropriate labels for these columns.\n",
    "- Geojson file that will generate a polygon of the relevant region\n",
    "    - For Chicago, this can be found at:\n",
    "        - https://data.cityofchicago.org/Facilities-Geographic-Boundaries/Boundaries-Community-Areas-current-/cauq-8yn6\n",
    "    - For regions of the UK, here is one process of generating a file from Ordnance Survey data:\n",
    "        - Visit https://www.ordnancesurvey.co.uk/opendatadownload/products.html\n",
    "        - Scroll down to the \"Boundary-Line\" data, select ESRI SHAPE format, click the \"Download\" box, then scroll to the bottom and click \"Continue\".\n",
    "        - After requesting the download from the next page, wait for a download link to be sent to your email, which should allow you to download a \"force_kmls.zip\" file full of .kml files.\n",
    "        - Use the \"ogr2ogr\" tool to convert the relevant .kml file to .geojson, as in the following command: \"ogr2ogr -f GeoJSON durham.geojson durham.kml\"\n",
    "        - The resulting GeoJSON file will have its coordinates in longitude an latitude. Optionally, you may convert that geojson file to a new one that has a UK-specific projection (EPSG 27700); this can be done with the function convertGeojsonUKCounty in onetimeruns.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "\n",
    "Set your parameters here. The current default arguments are for a Fantasy Durham data set; examples of further options are shown on commented-out lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter assignment complete.\n"
     ]
    }
   ],
   "source": [
    "### Edit these parameters, then run this.\n",
    "\n",
    "\n",
    "# Your input directory, containg your input data files discussed above\n",
    "input_datadir = \"../../Input\"\n",
    "\n",
    "# Your intended directory for the output files that will be generated\n",
    "output_datadir = \"../../Output\"\n",
    "\n",
    "# Name of your input csv file of crime data\n",
    "in_csv_file_name = \"Fantasy-Durham-Data.csv\"\n",
    "\n",
    "# Names of the appropriate columns in the header of the csv file\n",
    "#    column with date (and possibly time)\n",
    "csv_date_name       = \"Date\"\n",
    "#    column with eastings or longitudes\n",
    "csv_east_name       = \"Longitude\"\n",
    "#    column with northings or latitudes\n",
    "csv_north_name      = \"Latitude\"\n",
    "#    column with type of crime\n",
    "csv_crimetypes_name = \"Crime type\"\n",
    "\n",
    "# Name of your input GeoJSON file of the relevant region\n",
    "area_geojson_file_name = \"Police_Force_Areas_December_2016_Durham_fixed.geojson\"\n",
    "\n",
    "# Concise name for your crime data set, to be included as part of output file names\n",
    "#  Note: Any characters that are not letters or numbers will be removed\n",
    "dataset_name = \"FantDurFORE\"\n",
    "\n",
    "# Relevant crime types, as named in the crime type column of your input file\n",
    "#  If you want to aggregate multiple crime types, you can separate them by commas\n",
    "#crime_type_set = \"Burglary, Vehicle crime\"\n",
    "crime_type_set = \"Burglary\"\n",
    "#crime_type_set = \"Vehicle crime\"\n",
    "\n",
    "# Size (in meters) of the side of squares in the grid over the area\n",
    "cell_width = 500\n",
    "\n",
    "\n",
    "\n",
    "# The date associated with the experiment\n",
    "#  This should be the first day AFTER the intended training data window.\n",
    "#  If set to None or \"today\", this will default to today's date.\n",
    "#  (Currently, provide date in format \"YYYY-MM-DD\")\n",
    "exp_date = \"2019-09-15\"\n",
    "\n",
    "# For time length parameters, use a number followed by a letter.\n",
    "#  D=days, W=weeks, M=months, Y=years\n",
    "#  3D=3 days, 12W=12 weeks, 6M=6 months, 1Y=1 year, etc\n",
    "\n",
    "# Size of the time window of events for the models to be trained on in each experiment\n",
    "train_len          = \"4W\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Predictive model(s) to run, comma-separated if running multiple different ones\n",
    "#  Currently recognised names ares: random, naive, ideal, phs\n",
    "models_to_run = \"random,naive,ideal,phs\"\n",
    "\n",
    "\n",
    "# Parameters for PHS model, each one comma-separated as needed\n",
    "#  Atomic unit for time bandwidths\n",
    "phs_time_units = \"1W\"\n",
    "#  Time bandwidths -- should be a multiple of phs_time_units\n",
    "phs_time_bands = \"4W\"\n",
    "#  Atomic unit for distance bandwidths, in meters\n",
    "#   Recommended to set this equal to cell_width\n",
    "phs_dist_units = \"500\"\n",
    "#  Distance bandwidths, in meters -- should be a multiple of phs_dist_units\n",
    "phs_dist_bands = \"1500\"\n",
    "#  Weight function\n",
    "#   \"classic\": \n",
    "#   \"linear\": \n",
    "phs_weight = \"classic\"\n",
    "#  Spread type\n",
    "#   \"grid\": \n",
    "#   \"continuous\": \n",
    "phs_spread = \"continuous\"\n",
    "\n",
    "# CSV formatting parameters\n",
    "# If Fantasy Durham data:\n",
    "local_epsg = 27700\n",
    "csv_date_format = \"%d/%m/%Y\"\n",
    "csv_longlat = True\n",
    "csv_epsg = 27700\n",
    "csv_infeet = False\n",
    "\n",
    "\n",
    "\n",
    "print(\"Parameter assignment complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments using various models and data subsets\n",
    "\n",
    "This function (runModelExperiments) takes the parameters from above and runs the models with all desired parameter combinations, using training and testing data sets over sliding-window timeframes.\n",
    "\n",
    "A csv output file will appear in the defined data directory, containing results from each model with each parameter combination on each timeframe's data set.\n",
    "\n",
    "If only 1 data timeframe is used, heatmap visualisations will be generated, appearing below as well as in the same defined data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data directory is: ../../Input\n",
      "The output data directory is: ../../Output\n",
      "Number of experiments to run: 1\n",
      "Associated dates of each experiment: ['2019-09-15']\n",
      "Obtaining full data set and region...\n",
      "Number of relevant crimes: 987\n",
      "Number of relevant crimes in area: 987\n",
      "...Obtained full data set and region.\n",
      "Time taken to obtain data: 1.263\n",
      "Running experiment 1/1...\n",
      "Writing training data to ../../Output/train_200203_FantDurFORE_Burglary_500m_190915_1x_0D_4W_0D_1.geojson\n",
      "num_crimes_train: 281\n",
      "num_crimes_test: 0\n",
      "Running model: random\n",
      "Running model: naive\n",
      "Running model: ideal\n",
      "Running model: phs\n",
      " Parameter set #1/1\n",
      "Saving detailed results to csv:\n",
      "../../Output/details_200203_FantDurFORE_Burglary_500m_190915_1x_0D_4W_0D_1.csv\n",
      "       cell_num  coverage random_cell  random_cell_risk  random_found_count  \\\n",
      "0             1  0.000099    (56, 99)          0.999978                   0   \n",
      "1             2  0.000198    (35, 41)          0.999957                   0   \n",
      "2             3  0.000297   (19, 100)          0.999949                   0   \n",
      "3             4  0.000396    (23, 51)          0.999931                   0   \n",
      "4             5  0.000495    (6, 110)          0.999809                   0   \n",
      "...         ...       ...         ...               ...                 ...   \n",
      "10096     10097  0.999604   (59, 127)          0.000254                   0   \n",
      "10097     10098  0.999703   (73, 125)          0.000207                   0   \n",
      "10098     10099  0.999802    (53, 16)          0.000150                   0   \n",
      "10099     10100  0.999901    (14, 39)          0.000074                   0   \n",
      "10100     10101  1.000000   (26, 112)          0.000072                   0   \n",
      "\n",
      "       random_found_rate naive_cell  naive_cell_risk  naive_found_count  \\\n",
      "0                      0  (70, 134)              7.0                  0   \n",
      "1                      0  (16, 105)              5.0                  0   \n",
      "2                      0  (72, 100)              4.0                  0   \n",
      "3                      0  (18, 102)              3.0                  0   \n",
      "4                      0  (36, 101)              3.0                  0   \n",
      "...                  ...        ...              ...                ...   \n",
      "10096                  0  (103, 79)              0.0                  0   \n",
      "10097                  0  (103, 80)              0.0                  0   \n",
      "10098                  0  (104, 78)              0.0                  0   \n",
      "10099                  0  (104, 79)              0.0                  0   \n",
      "10100                  0  (104, 80)              0.0                  0   \n",
      "\n",
      "       naive_found_rate ideal_cell  ideal_cell_risk  ideal_found_count  \\\n",
      "0                     0    (0, 49)              0.0                  0   \n",
      "1                     0    (0, 50)              0.0                  0   \n",
      "2                     0    (0, 51)              0.0                  0   \n",
      "3                     0    (0, 52)              0.0                  0   \n",
      "4                     0    (0, 53)              0.0                  0   \n",
      "...                 ...        ...              ...                ...   \n",
      "10096                 0  (103, 79)              0.0                  0   \n",
      "10097                 0  (103, 80)              0.0                  0   \n",
      "10098                 0  (104, 78)              0.0                  0   \n",
      "10099                 0  (104, 79)              0.0                  0   \n",
      "10100                 0  (104, 80)              0.0                  0   \n",
      "\n",
      "       ideal_found_rate phs-4W-1500m_cell  phs-4W-1500m_cell_risk  \\\n",
      "0                     0         (70, 133)                3.872764   \n",
      "1                     0         (17, 103)                3.632779   \n",
      "2                     0         (70, 132)                3.464808   \n",
      "3                     0         (69, 132)                3.428359   \n",
      "4                     0         (69, 133)                3.343946   \n",
      "...                 ...               ...                     ...   \n",
      "10096                 0         (101, 75)                0.000000   \n",
      "10097                 0         (102, 72)                0.000000   \n",
      "10098                 0         (102, 73)                0.000000   \n",
      "10099                 0         (102, 74)                0.000000   \n",
      "10100                 0         (102, 75)                0.000000   \n",
      "\n",
      "       phs-4W-1500m_found_count  phs-4W-1500m_found_rate  \n",
      "0                             0                        0  \n",
      "1                             0                        0  \n",
      "2                             0                        0  \n",
      "3                             0                        0  \n",
      "4                             0                        0  \n",
      "...                         ...                      ...  \n",
      "10096                         0                        0  \n",
      "10097                         0                        0  \n",
      "10098                         0                        0  \n",
      "10099                         0                        0  \n",
      "10100                         0                        0  \n",
      "\n",
      "[10101 rows x 18 columns]\n",
      "../../Output/details_200203_FantDurFORE_Burglary_500m_190915_1x_0D_4W_0D_1.csv\n",
      "Saving results to geojson:\n",
      "../../Output/results_200203_FantDurFORE_Burglary_500m_190915_1x_0D_4W_0D.geojson\n",
      "Time spent on experiment: 7.435\n",
      "Experiment timing info:\n",
      "Exp #\tTime\n",
      "1\t7.435\n",
      "Output file names:\n",
      "../../Output/train_200203_FantDurFORE_Burglary_500m_190915_1x_0D_4W_0D_1.geojson\n",
      "../../Output/details_200203_FantDurFORE_Burglary_500m_190915_1x_0D_4W_0D_1.csv\n",
      "../../Output/results_200203_FantDurFORE_Burglary_500m_190915_1x_0D_4W_0D.geojson\n"
     ]
    }
   ],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "created_files = runModelExperiments(\n",
    "        input_datadir_in = input_datadir, \n",
    "        output_datadir_in = output_datadir, \n",
    "        dataset_name_in = dataset_name, \n",
    "        crime_type_set_in = crime_type_set, \n",
    "        cell_width_in = cell_width, \n",
    "        in_csv_file_name_in = in_csv_file_name, \n",
    "        geojson_file_name_in = area_geojson_file_name, \n",
    "        local_epsg_in = local_epsg, \n",
    "        earliest_exp_date_in = exp_date, \n",
    "        train_len_in = train_len, \n",
    "        test_len_in = \"0D\", \n",
    "        models_to_run_in = models_to_run, \n",
    "        phs_time_units_in = phs_time_units, \n",
    "        phs_time_bands_in = phs_time_bands, \n",
    "        phs_dist_units_in = phs_dist_units, \n",
    "        phs_dist_bands_in = phs_dist_bands, \n",
    "        phs_weight_in = phs_weight, \n",
    "        phs_spread_in = phs_spread, \n",
    "        csv_date_format = csv_date_format, \n",
    "        csv_longlat = csv_longlat, \n",
    "        csv_epsg = csv_epsg, \n",
    "        csv_infeet = csv_infeet, \n",
    "        csv_col_names = [csv_date_name, csv_east_name, csv_north_name, csv_crimetypes_name], \n",
    "        )\n",
    "\n",
    "train_geojson_file, details_csv_file, results_geojson_file = created_files\n",
    "print(\"Output file names:\")\n",
    "for fname in created_files:\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a detailed csv file has been generated, a line graph of the results can be viewed by running this code, after editing the parameters appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optionally, edit this then run it\n",
    "\n",
    "# Full path to the details csv file\n",
    "details_csv = \"../../Output/details_200130_FantDur_Burglary_500m_190915_1x_1W_4W_1W_1.csv\"\n",
    "\n",
    "# Bounds of the x-axis, corresponding to coverage rate\n",
    "coverage_range = [0, 0.1]\n",
    "\n",
    "# Title for the graph (if no title, set to None)\n",
    "#graph_title = None\n",
    "graph_title = \"Coverage vs Hit Rate\"\n",
    "\n",
    "# Dimensions of output graph (if None, will be (12,6))\n",
    "graph_size = None\n",
    "graph_size = (12,8)\n",
    "\n",
    "\n",
    "# If you want to save the line graph, provide a file name here\n",
    "img_file_path = None\n",
    "#img_file_path = \"../../Output/details_200130_FantDur_Burglary_500m_190915_1x_1W_4W_1W_1.png\"\n",
    "\n",
    "\n",
    "graph_cov_vs_hit_from_csv(details_csv, \n",
    "                          x_limits = coverage_range, \n",
    "                          title = graph_title, \n",
    "                          img_size = graph_size, \n",
    "                          out_img_file_path = img_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conda installing Ipyleaflet, we need to enable some notebook extensions and import its functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "!jupyter nbextension enable --py --sys-prefix ipyleaflet\n",
    "from ipyleaflet import *\n",
    "print(\"Successfully imported ipyleaflet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you successfully ran runModelExperiments above, performing only one experiment so that a \"results\" GeoJSON file is generated, then these file paths to the GeoJSON files will already be saved, so you don't need to run this section.\n",
    "\n",
    "However, if you want to examine a different previously created file, then you can declare the full paths of those GeoJSON files yourself, here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional; only edit & run this if desired\n",
    "\n",
    "# Name of GeoJson file with training data's events\n",
    "train_geojson_file = \"../../Data/train_200115_FantDur_190901_1W_1W_4W_1W.geojson\"\n",
    "\n",
    "# Name of GeoJson file with risk scores for relevant cells\n",
    "results_geojson_file = \"../../Data/results_200115_FantDur_190901_1W_1W_4W_1W.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from the results GeoJSON file, and display a list of properties from the results GeoJSON that can be selected for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this without editing\n",
    "\n",
    "with open(results_geojson_file) as cg:\n",
    "    cell_results = json.load(cg)\n",
    "print(\"Successfully read geojson data.\\n\")\n",
    "\n",
    "print('Properties available to visualize as \"property_to_map\":\\n')\n",
    "for p in list_risk_model_properties(geojson_file_contents=cell_results):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use this section if you want to combine properties together to make a new property, which will be saved off into a new GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional; only edit & run this if desired\n",
    "\n",
    "# The geojson data (or, file names) with the info you want to combine.\n",
    "# If it's all from the same data, just give the file name or the data object\n",
    "# If you're pulling from multiple geojson files, make a list of them, \n",
    "#  repeating them for as many properties you're taking from them.\n",
    "# For example, if you're combining 2 properties from geojsonA and 1 property\n",
    "#  from geojsonB, this would be [geojsonA, geojsonA, geojsonB]\n",
    "\n",
    "geojson_data_to_combine = [\"../../Output/results_200129_FantDur_Burglary_500m_190915_1x_1W_4W_1W.geojson\", \n",
    "                           \"../../Output/results_200129_FantDur_Burglary_500m_190915_1x_1W_4W_1W.geojson\"]\n",
    "\n",
    "# The crime type analysed for each file\n",
    "crime_type_set = \"Burglary, Vehicle crime\"\n",
    "\n",
    "# The names of the properties you're combining.\n",
    "# If it's the same property name from all the geojsons, just name it here.\n",
    "# If you want multiple properties, make a list of them here,\n",
    "#  corresponding to the list of geojsons in geojson_data_to_combine\n",
    "\n",
    "properties_to_combine = \"phs-4W-1500m, phs-4W-1500m\"\n",
    "\n",
    "# The relative weights to place on each property.\n",
    "# For example, if you consider the second property to be three times as \n",
    "#  important as the first property, then use [1, 3] here.\n",
    "# That would create a new property that is equal to the sum of\n",
    "#  the first property and treble the second property.\n",
    "\n",
    "property_weights = [2,1]\n",
    "\n",
    "# The name for the new combined property you create.\n",
    "# If this is not included or set to None, then the name of the property\n",
    "#  will be the names of all the other properties, combined with \"_\"\n",
    "\n",
    "combined_property_name = \"triple-test\"\n",
    "\n",
    "# The name for the output GeoJSON file containing the combined property.\n",
    "# If this is not included or set to None, then the name of the file\n",
    "#  will be \"results_{combined_property_name}.geojson\" and it will be\n",
    "#  placed in the same directory as the first GeoJSON file listed in\n",
    "#  the list geojson_data_to_combine.\n",
    "\n",
    "combined_geojson_file_path = None\n",
    "\n",
    "# The combined property is created here\n",
    "\n",
    "cell_results, new_property_name, new_geojson_file = combine_geojson_features(\n",
    "                        geojson_data_list     = geojson_data_to_combine, \n",
    "                        combine_property_list = properties_to_combine, \n",
    "                        multiplier_list       = property_weights, \n",
    "                        new_property_name     = combined_property_name, \n",
    "                        new_file_name         = combined_geojson_file_path, \n",
    "                        )\n",
    "\n",
    "print(f\"Combined properties to make new property: {new_property_name}\")\n",
    "print(f\"New GeoJSON file saved at: {new_geojson_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name the property you want to view on an interactive map here, along with other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edit this, then run it\n",
    "\n",
    "# The property you want to map from the results file\n",
    "#property_to_map = \"naive\"\n",
    "property_to_map = \"phs-4W-1500m\"\n",
    "#property_to_map = \"phs-combo\"\n",
    "\n",
    "# The top proportion of cells you want to highlight\n",
    "highlight_portion = 0.01\n",
    "\n",
    "# The style of highlighted cells\n",
    "highlight_cell_style = {'color':'blue',\n",
    "                        'weight':1.5,\n",
    "                        'fillColor':'transparent',\n",
    "                       }\n",
    "\n",
    "# Whether you want to plot the events from the training data\n",
    "#  Choose from:\n",
    "#   \"none\"    : Do not display the events\n",
    "#   \"point\"   : Each event is a slightly transparent black circle\n",
    "#   \"cluster\" : Multiple events cluster together as single circles,\n",
    "#                 changing at different zoom levels\n",
    "show_training_events = \"cluster\"\n",
    "\n",
    "# Whether you want to save the top proportion of cells as a GeoJSON\n",
    "#  file for later use, perhaps focusing solely on those areas.\n",
    "#  This will create a file in the ouput directory, with a name\n",
    "#  formatted as \"top-cells_(property name)_(proportion).geojson\"\n",
    "save_top_cells = True\n",
    "\n",
    "print(\"Parameters for map display have been set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Run this without editing anything\n",
    "\n",
    "# Instantiate a map centred at Durham\n",
    "#m = Map(center=[54.776100, -1.573300], zoom=10)\n",
    "m = Map(center=[54.75, -1.573300], zoom=9)\n",
    "\n",
    "# We now load the police force area GeoJSON file and add it as a layer to the map\n",
    "with open(std_file_name([input_datadir, area_geojson_file_name]), 'r') as f:\n",
    "    bounds = json.load(f)\n",
    "bounds_layer = GeoJSON(data=bounds, style = {'color': 'green', 'opacity':1, 'weight':2, 'fillColor':'transparent'})\n",
    "m.add_layer(bounds_layer)\n",
    "\n",
    "# Obtain relevant scores from GeoJSON file, and only include\n",
    "#  cells with non-zero scores\n",
    "score_mapping = dict()\n",
    "nonzero_cell_results = dict()\n",
    "for key in cell_results:\n",
    "    if key != 'features':\n",
    "        nonzero_cell_results[key] = cell_results[key]\n",
    "nonzero_cell_results['features'] = []\n",
    "for feat in cell_results['features']:\n",
    "    property_value = feat['properties'][property_to_map]\n",
    "    if property_value > 0:\n",
    "        nonzero_cell_results['features'].append(feat)\n",
    "    score_mapping[feat['id']] = property_value\n",
    "\n",
    "\n",
    "# Create map layer with color-coded cells reperenting risk scores, like a heat map\n",
    "from branca.colormap import linear\n",
    "layer = Choropleth(\n",
    "    geo_data=nonzero_cell_results,\n",
    "    choro_data=score_mapping,\n",
    "    colormap=linear.YlOrRd_04,\n",
    "    border_color='transparent',\n",
    "    style={'fillOpacity': 0.8})\n",
    "m.add_layer(layer)\n",
    "\n",
    "\n",
    "# Create map layer with circles representing crime events\n",
    "if show_training_events != None:\n",
    "    show_training_events = show_training_events.lower()\n",
    "    if show_training_events not in [\"false\",\"no\",\"none\"]:\n",
    "        if show_training_events == \"point\":\n",
    "            with open(train_geojson_file) as eg:\n",
    "                datapoints = json.load(eg)\n",
    "            geojson_datapoints = GeoJSON(data=datapoints, point_style={'color': 'transparent', 'fillColor': 'black', 'radius': 5})\n",
    "            m.add_layer(geojson_datapoints)\n",
    "        elif show_training_events == \"cluster\":\n",
    "            cluster_datapoints = marker_cluster_from_data(train_geojson_file)\n",
    "            m.add_layer(cluster_datapoints)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create map layer where top % of cells are highlighted\n",
    "cell_results_gdf = json_dict_to_geoframe(cell_results)\n",
    "top_cells_frame = top_geojson_features(cell_results_gdf, property_to_map, highlight_portion)\n",
    "top_cells_layer = GeoData(geo_dataframe = top_cells_frame,\n",
    "                         style = highlight_cell_style)\n",
    "m.add_layer(top_cells_layer)\n",
    "if save_top_cells:\n",
    "    top_cells_geojson_file = std_file_name([output_datadir, \n",
    "                f\"top-cells_{property_to_map}_{str(highlight_portion)[2:]}.geojson\"])\n",
    "    cell_results_gdf.to_file(top_cells_geojson_file, driver='GeoJSON')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add useful controls to the GUI for full screen mode and layer toggling\n",
    "m.add_control(FullScreenControl())\n",
    "m.add_control(LayersControl())\n",
    "\n",
    "\n",
    "# Display useful information as text above the map\n",
    "num_cells = len(cell_results['features'])\n",
    "sqkm_per_cell = ((cell_width*.001)**2)\n",
    "area_size = num_cells * sqkm_per_cell\n",
    "num_cells_highlight = int(num_cells * highlight_portion)\n",
    "area_highlight = num_cells_highlight * sqkm_per_cell\n",
    "date_time_now = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M\")\n",
    "message = (\n",
    "    f\"Generating map...... {date_time_now}\\n\", \n",
    "    f\"Crime Type Analysed: {crime_type_set}\\n\", \n",
    "    f\"Mapping: {property_to_map}\\n\", \n",
    "    f\"Grid Config:\\n\",\n",
    "    f\"  Grid cell size: {cell_width}m x {cell_width}m\\n\",\n",
    "    f\"  {num_cells} grid cells analysed\\n\",\n",
    "    f\"  Total area: {area_size:.2f} km^2 \\n\",\n",
    "    f\"Priority Cells:\\n\",\n",
    "    f\"  Coverage {highlight_portion * 100}%\\n\",\n",
    "    f\"  Number of cells: {num_cells_highlight}\\n\",\n",
    "    f\"  Priority area: {area_highlight:.2f} km^2\\n\",\n",
    ")\n",
    "print(*message)\n",
    "\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
